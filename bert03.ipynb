{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":8255088,"sourceType":"datasetVersion","datasetId":4898798}],"dockerImageVersionId":30699,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-04-28T16:32:37.462458Z","iopub.execute_input":"2024-04-28T16:32:37.463026Z","iopub.status.idle":"2024-04-28T16:32:38.314692Z","shell.execute_reply.started":"2024-04-28T16:32:37.462996Z","shell.execute_reply":"2024-04-28T16:32:38.313614Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/dataset02/labeled_data.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport os, re\n\nimport matplotlib.pyplot as plt\n\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\nfrom transformers import BertTokenizer, BertForSequenceClassification, AdamW, get_linear_schedule_with_warmup\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import matthews_corrcoef, classification_report\nimport time\nimport datetime","metadata":{"execution":{"iopub.status.busy":"2024-04-28T16:33:40.362313Z","iopub.execute_input":"2024-04-28T16:33:40.362852Z","iopub.status.idle":"2024-04-28T16:33:47.501599Z","shell.execute_reply.started":"2024-04-28T16:33:40.362819Z","shell.execute_reply":"2024-04-28T16:33:47.500772Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"# Fine-Tuning Parameters\nlearning_rate = 2e-5\nbatch_size = 32\nepochs = 20  # Adjust the number of epochs as needed\n\n# Load the data\ndf = pd.read_csv('/kaggle/input/dataset02/labeled_data.csv')\n\n# Function to clean tweets\ndef strip_all_entities(x):\n    return ' '.join(re.sub(\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)\", \" \", x).split())\n\n# Apply tweet cleaning\ndf['tweet'] = df['tweet'].apply(strip_all_entities)\n\n# Train-test-validation split\ntrain, Teal = train_test_split(df, random_state=1508, shuffle=True, test_size=0.2)\ntest, validation = train_test_split(Teal, random_state=1508, shuffle=True, test_size=0.5)\n\n# Get the lists of sentences and their labels\ntrn_sentences = train['tweet'].values\ntrain_labels = train['class'].values\n\ntst_sentences = test['tweet'].values\ntest_labels = test['class'].values\n\nval_sentences = validation['tweet'].values\nvalidation_labels = validation['class'].values\n\n# Load BERT tokenizer\ntokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)","metadata":{"execution":{"iopub.status.busy":"2024-04-28T16:34:24.405960Z","iopub.execute_input":"2024-04-28T16:34:24.406499Z","iopub.status.idle":"2024-04-28T16:34:25.897234Z","shell.execute_reply.started":"2024-04-28T16:34:24.406469Z","shell.execute_reply":"2024-04-28T16:34:25.896191Z"},"trusted":true},"execution_count":3,"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4b48c410ade742f49e26bc9520c75000"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"159eb3f4bf864850b96502d6da667108"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dd8f713c898640ef9164149b158b6c96"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d89a3b11075741cebaee85775cc9d326"}},"metadata":{}}]},{"cell_type":"code","source":"# Function to encode sentences and apply padding and masking\ndef bert_encode(data, max_len):\n    input_ids = []\n    attention_masks = []\n\n    for i in range(len(data)):\n        encoded = tokenizer.encode_plus(data[i],\n                                         add_special_tokens=True,\n                                         max_length=max_len,\n                                         padding='max_length',\n                                         truncation=True,\n                                         return_attention_mask=True)\n\n        input_ids.append(encoded['input_ids'])\n        attention_masks.append(encoded['attention_mask'])\n\n    return np.array(input_ids), np.array(attention_masks)\n\n# Encode sentences for BERT input\nMAX_LEN = 128  # Experiment with different sequence lengths\ntrain_inputs, train_masks = bert_encode(trn_sentences, MAX_LEN)\nvalidation_inputs, validation_masks = bert_encode(val_sentences, MAX_LEN)\n\n# Convert data to PyTorch tensors\ntrain_inputs = torch.tensor(train_inputs)\nvalidation_inputs = torch.tensor(validation_inputs)\ntrain_labels = torch.tensor(train_labels)\nvalidation_labels = torch.tensor(validation_labels)\ntrain_masks = torch.tensor(train_masks)\nvalidation_masks = torch.tensor(validation_masks)\n\n# Create DataLoader for training and validation sets\ntrain_data = TensorDataset(train_inputs, train_masks, train_labels)\ntrain_sampler = RandomSampler(train_data)\ntrain_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\nvalidation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\nvalidation_sampler = SequentialSampler(validation_data)\nvalidation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)\n\n# Load pre-trained BERT model for sequence classification\nmodel = BertForSequenceClassification.from_pretrained(\n    \"bert-base-uncased\",\n    num_labels=3,\n    output_attentions=False,\n    output_hidden_states=False,\n)\nmodel.cuda()\n","metadata":{"execution":{"iopub.status.busy":"2024-04-28T16:35:03.128442Z","iopub.execute_input":"2024-04-28T16:35:03.128833Z","iopub.status.idle":"2024-04-28T16:35:20.667242Z","shell.execute_reply.started":"2024-04-28T16:35:03.128802Z","shell.execute_reply":"2024-04-28T16:35:20.666220Z"},"trusted":true},"execution_count":4,"outputs":[{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"618f5f1ab44f49bea36312dffade3030"}},"metadata":{}},{"name":"stderr","text":"Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"BertForSequenceClassification(\n  (bert): BertModel(\n    (embeddings): BertEmbeddings(\n      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n      (position_embeddings): Embedding(512, 768)\n      (token_type_embeddings): Embedding(2, 768)\n      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (encoder): BertEncoder(\n      (layer): ModuleList(\n        (0-11): 12 x BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n    (pooler): BertPooler(\n      (dense): Linear(in_features=768, out_features=768, bias=True)\n      (activation): Tanh()\n    )\n  )\n  (dropout): Dropout(p=0.1, inplace=False)\n  (classifier): Linear(in_features=768, out_features=3, bias=True)\n)"},"metadata":{}}]},{"cell_type":"code","source":"# Set device to GPU if available, otherwise CPU\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\nimport time\nimport datetime\n\ndef format_time(elapsed):\n    '''\n    Takes a time in seconds and returns a string hh:mm:ss\n    '''\n    # Round to the nearest second.\n    elapsed_rounded = int(round((elapsed)))\n\n    # Format as hh:mm:ss\n    return str(datetime.timedelta(seconds=elapsed_rounded))","metadata":{"execution":{"iopub.status.busy":"2024-04-28T16:37:13.456924Z","iopub.execute_input":"2024-04-28T16:37:13.457710Z","iopub.status.idle":"2024-04-28T16:37:13.464001Z","shell.execute_reply.started":"2024-04-28T16:37:13.457677Z","shell.execute_reply":"2024-04-28T16:37:13.462890Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"def flat_accuracy(preds, labels):\n    pred_flat = np.argmax(preds, axis=1).flatten()\n    labels_flat = labels.flatten()\n    return np.sum(pred_flat == labels_flat) / len(labels_flat)","metadata":{"execution":{"iopub.status.busy":"2024-04-28T16:54:25.611900Z","iopub.execute_input":"2024-04-28T16:54:25.612279Z","iopub.status.idle":"2024-04-28T16:54:25.617774Z","shell.execute_reply.started":"2024-04-28T16:54:25.612249Z","shell.execute_reply":"2024-04-28T16:54:25.616639Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"# Define optimizer and learning rate scheduler\noptimizer = AdamW(model.parameters(), lr=learning_rate, eps=1e-8)\ntotal_steps = len(train_dataloader) * epochs\nscheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=total_steps)\n\n# Regularization\nmodel.dropout = nn.Dropout(0.1)  # Experiment with dropout rate\n\n# Training Loop\nloss_values = []\nfor epoch_i in range(epochs):\n    print(\"\")\n    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n    print('Training...')\n    t0 = time.time()\n    total_loss = 0\n    model.train()\n    for step, batch in enumerate(train_dataloader):\n        if step % 40 == 0 and not step == 0:\n            elapsed = format_time(time.time() - t0)\n            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n        b_input_ids = batch[0].to(device)\n        b_input_mask = batch[1].to(device)\n        b_labels = batch[2].to(device)\n        model.zero_grad()\n        outputs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask, labels=b_labels)\n        loss = outputs[0]\n        total_loss += loss.item()\n        loss.backward()\n        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n        optimizer.step()\n        scheduler.step()\n    avg_train_loss = total_loss / len(train_dataloader)\n    loss_values.append(avg_train_loss)\n    print(\"\")\n    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n    print(\"  Training epoch took: {:}\".format(format_time(time.time() - t0)))\n    \n    # Evaluation on validation set after each epoch\n    print(\"\")\n    print(\"Running Validation...\")\n    model.eval()\n    eval_loss, eval_accuracy = 0, 0\n    nb_eval_steps, nb_eval_examples = 0, 0\n    for batch in validation_dataloader:\n        batch = tuple(t.to(device) for t in batch)\n        b_input_ids, b_input_mask, b_labels = batch\n        with torch.no_grad():\n            outputs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)\n        logits = outputs[0]\n        logits = logits.detach().cpu().numpy()\n        label_ids = b_labels.to('cpu').numpy()\n        tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n        eval_accuracy += tmp_eval_accuracy\n        nb_eval_steps += 1\n    print(\"  Accuracy: {0:.2f}\".format(eval_accuracy / nb_eval_steps))\n    print(\"  Validation took: {:}\".format(format_time(time.time() - t0)))\n","metadata":{"execution":{"iopub.status.busy":"2024-04-28T16:54:27.690695Z","iopub.execute_input":"2024-04-28T16:54:27.691559Z","iopub.status.idle":"2024-04-28T19:07:58.274330Z","shell.execute_reply.started":"2024-04-28T16:54:27.691523Z","shell.execute_reply":"2024-04-28T19:07:58.273462Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"\n======== Epoch 1 / 20 ========\nTraining...\n  Batch    40  of    620.    Elapsed: 0:00:25.\n  Batch    80  of    620.    Elapsed: 0:00:50.\n  Batch   120  of    620.    Elapsed: 0:01:15.\n  Batch   160  of    620.    Elapsed: 0:01:39.\n  Batch   200  of    620.    Elapsed: 0:02:04.\n  Batch   240  of    620.    Elapsed: 0:02:29.\n  Batch   280  of    620.    Elapsed: 0:02:54.\n  Batch   320  of    620.    Elapsed: 0:03:19.\n  Batch   360  of    620.    Elapsed: 0:03:43.\n  Batch   400  of    620.    Elapsed: 0:04:08.\n  Batch   440  of    620.    Elapsed: 0:04:33.\n  Batch   480  of    620.    Elapsed: 0:04:58.\n  Batch   520  of    620.    Elapsed: 0:05:23.\n  Batch   560  of    620.    Elapsed: 0:05:47.\n  Batch   600  of    620.    Elapsed: 0:06:12.\n\n  Average training loss: 0.17\n  Training epoch took: 0:06:24\n\nRunning Validation...\n  Accuracy: 0.92\n  Validation took: 0:06:41\n\n======== Epoch 2 / 20 ========\nTraining...\n  Batch    40  of    620.    Elapsed: 0:00:25.\n  Batch    80  of    620.    Elapsed: 0:00:50.\n  Batch   120  of    620.    Elapsed: 0:01:14.\n  Batch   160  of    620.    Elapsed: 0:01:39.\n  Batch   200  of    620.    Elapsed: 0:02:04.\n  Batch   240  of    620.    Elapsed: 0:02:29.\n  Batch   280  of    620.    Elapsed: 0:02:54.\n  Batch   320  of    620.    Elapsed: 0:03:18.\n  Batch   360  of    620.    Elapsed: 0:03:43.\n  Batch   400  of    620.    Elapsed: 0:04:08.\n  Batch   440  of    620.    Elapsed: 0:04:33.\n  Batch   480  of    620.    Elapsed: 0:04:57.\n  Batch   520  of    620.    Elapsed: 0:05:22.\n  Batch   560  of    620.    Elapsed: 0:05:47.\n  Batch   600  of    620.    Elapsed: 0:06:12.\n\n  Average training loss: 0.12\n  Training epoch took: 0:06:24\n\nRunning Validation...\n  Accuracy: 0.91\n  Validation took: 0:06:40\n\n======== Epoch 3 / 20 ========\nTraining...\n  Batch    40  of    620.    Elapsed: 0:00:25.\n  Batch    80  of    620.    Elapsed: 0:00:50.\n  Batch   120  of    620.    Elapsed: 0:01:14.\n  Batch   160  of    620.    Elapsed: 0:01:39.\n  Batch   200  of    620.    Elapsed: 0:02:04.\n  Batch   240  of    620.    Elapsed: 0:02:29.\n  Batch   280  of    620.    Elapsed: 0:02:53.\n  Batch   320  of    620.    Elapsed: 0:03:18.\n  Batch   360  of    620.    Elapsed: 0:03:43.\n  Batch   400  of    620.    Elapsed: 0:04:08.\n  Batch   440  of    620.    Elapsed: 0:04:33.\n  Batch   480  of    620.    Elapsed: 0:04:57.\n  Batch   520  of    620.    Elapsed: 0:05:22.\n  Batch   560  of    620.    Elapsed: 0:05:47.\n  Batch   600  of    620.    Elapsed: 0:06:12.\n\n  Average training loss: 0.08\n  Training epoch took: 0:06:24\n\nRunning Validation...\n  Accuracy: 0.91\n  Validation took: 0:06:40\n\n======== Epoch 4 / 20 ========\nTraining...\n  Batch    40  of    620.    Elapsed: 0:00:25.\n  Batch    80  of    620.    Elapsed: 0:00:50.\n  Batch   120  of    620.    Elapsed: 0:01:14.\n  Batch   160  of    620.    Elapsed: 0:01:39.\n  Batch   200  of    620.    Elapsed: 0:02:04.\n  Batch   240  of    620.    Elapsed: 0:02:29.\n  Batch   280  of    620.    Elapsed: 0:02:54.\n  Batch   320  of    620.    Elapsed: 0:03:18.\n  Batch   360  of    620.    Elapsed: 0:03:43.\n  Batch   400  of    620.    Elapsed: 0:04:08.\n  Batch   440  of    620.    Elapsed: 0:04:33.\n  Batch   480  of    620.    Elapsed: 0:04:58.\n  Batch   520  of    620.    Elapsed: 0:05:22.\n  Batch   560  of    620.    Elapsed: 0:05:47.\n  Batch   600  of    620.    Elapsed: 0:06:12.\n\n  Average training loss: 0.05\n  Training epoch took: 0:06:24\n\nRunning Validation...\n  Accuracy: 0.91\n  Validation took: 0:06:41\n\n======== Epoch 5 / 20 ========\nTraining...\n  Batch    40  of    620.    Elapsed: 0:00:25.\n  Batch    80  of    620.    Elapsed: 0:00:49.\n  Batch   120  of    620.    Elapsed: 0:01:14.\n  Batch   160  of    620.    Elapsed: 0:01:39.\n  Batch   200  of    620.    Elapsed: 0:02:04.\n  Batch   240  of    620.    Elapsed: 0:02:28.\n  Batch   280  of    620.    Elapsed: 0:02:53.\n  Batch   320  of    620.    Elapsed: 0:03:18.\n  Batch   360  of    620.    Elapsed: 0:03:43.\n  Batch   400  of    620.    Elapsed: 0:04:08.\n  Batch   440  of    620.    Elapsed: 0:04:33.\n  Batch   480  of    620.    Elapsed: 0:04:57.\n  Batch   520  of    620.    Elapsed: 0:05:22.\n  Batch   560  of    620.    Elapsed: 0:05:47.\n  Batch   600  of    620.    Elapsed: 0:06:12.\n\n  Average training loss: 0.03\n  Training epoch took: 0:06:24\n\nRunning Validation...\n  Accuracy: 0.90\n  Validation took: 0:06:41\n\n======== Epoch 6 / 20 ========\nTraining...\n  Batch    40  of    620.    Elapsed: 0:00:25.\n  Batch    80  of    620.    Elapsed: 0:00:49.\n  Batch   120  of    620.    Elapsed: 0:01:14.\n  Batch   160  of    620.    Elapsed: 0:01:39.\n  Batch   200  of    620.    Elapsed: 0:02:04.\n  Batch   240  of    620.    Elapsed: 0:02:29.\n  Batch   280  of    620.    Elapsed: 0:02:53.\n  Batch   320  of    620.    Elapsed: 0:03:18.\n  Batch   360  of    620.    Elapsed: 0:03:43.\n  Batch   400  of    620.    Elapsed: 0:04:08.\n  Batch   440  of    620.    Elapsed: 0:04:33.\n  Batch   480  of    620.    Elapsed: 0:04:58.\n  Batch   520  of    620.    Elapsed: 0:05:22.\n  Batch   560  of    620.    Elapsed: 0:05:47.\n  Batch   600  of    620.    Elapsed: 0:06:12.\n\n  Average training loss: 0.02\n  Training epoch took: 0:06:24\n\nRunning Validation...\n  Accuracy: 0.91\n  Validation took: 0:06:41\n\n======== Epoch 7 / 20 ========\nTraining...\n  Batch    40  of    620.    Elapsed: 0:00:25.\n  Batch    80  of    620.    Elapsed: 0:00:50.\n  Batch   120  of    620.    Elapsed: 0:01:14.\n  Batch   160  of    620.    Elapsed: 0:01:39.\n  Batch   200  of    620.    Elapsed: 0:02:04.\n  Batch   240  of    620.    Elapsed: 0:02:29.\n  Batch   280  of    620.    Elapsed: 0:02:53.\n  Batch   320  of    620.    Elapsed: 0:03:18.\n  Batch   360  of    620.    Elapsed: 0:03:43.\n  Batch   400  of    620.    Elapsed: 0:04:08.\n  Batch   440  of    620.    Elapsed: 0:04:33.\n  Batch   480  of    620.    Elapsed: 0:04:57.\n  Batch   520  of    620.    Elapsed: 0:05:22.\n  Batch   560  of    620.    Elapsed: 0:05:47.\n  Batch   600  of    620.    Elapsed: 0:06:12.\n\n  Average training loss: 0.02\n  Training epoch took: 0:06:24\n\nRunning Validation...\n  Accuracy: 0.91\n  Validation took: 0:06:40\n\n======== Epoch 8 / 20 ========\nTraining...\n  Batch    40  of    620.    Elapsed: 0:00:25.\n  Batch    80  of    620.    Elapsed: 0:00:50.\n  Batch   120  of    620.    Elapsed: 0:01:14.\n  Batch   160  of    620.    Elapsed: 0:01:39.\n  Batch   200  of    620.    Elapsed: 0:02:04.\n  Batch   240  of    620.    Elapsed: 0:02:29.\n  Batch   280  of    620.    Elapsed: 0:02:53.\n  Batch   320  of    620.    Elapsed: 0:03:18.\n  Batch   360  of    620.    Elapsed: 0:03:43.\n  Batch   400  of    620.    Elapsed: 0:04:08.\n  Batch   440  of    620.    Elapsed: 0:04:33.\n  Batch   480  of    620.    Elapsed: 0:04:57.\n  Batch   520  of    620.    Elapsed: 0:05:22.\n  Batch   560  of    620.    Elapsed: 0:05:47.\n  Batch   600  of    620.    Elapsed: 0:06:12.\n\n  Average training loss: 0.02\n  Training epoch took: 0:06:24\n\nRunning Validation...\n  Accuracy: 0.90\n  Validation took: 0:06:40\n\n======== Epoch 9 / 20 ========\nTraining...\n  Batch    40  of    620.    Elapsed: 0:00:25.\n  Batch    80  of    620.    Elapsed: 0:00:50.\n  Batch   120  of    620.    Elapsed: 0:01:14.\n  Batch   160  of    620.    Elapsed: 0:01:39.\n  Batch   200  of    620.    Elapsed: 0:02:04.\n  Batch   240  of    620.    Elapsed: 0:02:29.\n  Batch   280  of    620.    Elapsed: 0:02:54.\n  Batch   320  of    620.    Elapsed: 0:03:18.\n  Batch   360  of    620.    Elapsed: 0:03:43.\n  Batch   400  of    620.    Elapsed: 0:04:08.\n  Batch   440  of    620.    Elapsed: 0:04:33.\n  Batch   480  of    620.    Elapsed: 0:04:58.\n  Batch   520  of    620.    Elapsed: 0:05:22.\n  Batch   560  of    620.    Elapsed: 0:05:47.\n  Batch   600  of    620.    Elapsed: 0:06:12.\n\n  Average training loss: 0.02\n  Training epoch took: 0:06:24\n\nRunning Validation...\n  Accuracy: 0.91\n  Validation took: 0:06:41\n\n======== Epoch 10 / 20 ========\nTraining...\n  Batch    40  of    620.    Elapsed: 0:00:25.\n  Batch    80  of    620.    Elapsed: 0:00:50.\n  Batch   120  of    620.    Elapsed: 0:01:14.\n  Batch   160  of    620.    Elapsed: 0:01:39.\n  Batch   200  of    620.    Elapsed: 0:02:04.\n  Batch   240  of    620.    Elapsed: 0:02:29.\n  Batch   280  of    620.    Elapsed: 0:02:53.\n  Batch   320  of    620.    Elapsed: 0:03:18.\n  Batch   360  of    620.    Elapsed: 0:03:43.\n  Batch   400  of    620.    Elapsed: 0:04:08.\n  Batch   440  of    620.    Elapsed: 0:04:33.\n  Batch   480  of    620.    Elapsed: 0:04:57.\n  Batch   520  of    620.    Elapsed: 0:05:22.\n  Batch   560  of    620.    Elapsed: 0:05:47.\n  Batch   600  of    620.    Elapsed: 0:06:12.\n\n  Average training loss: 0.01\n  Training epoch took: 0:06:24\n\nRunning Validation...\n  Accuracy: 0.91\n  Validation took: 0:06:41\n\n======== Epoch 11 / 20 ========\nTraining...\n  Batch    40  of    620.    Elapsed: 0:00:25.\n  Batch    80  of    620.    Elapsed: 0:00:50.\n  Batch   120  of    620.    Elapsed: 0:01:15.\n  Batch   160  of    620.    Elapsed: 0:01:39.\n  Batch   200  of    620.    Elapsed: 0:02:04.\n  Batch   240  of    620.    Elapsed: 0:02:29.\n  Batch   280  of    620.    Elapsed: 0:02:53.\n  Batch   320  of    620.    Elapsed: 0:03:18.\n  Batch   360  of    620.    Elapsed: 0:03:43.\n  Batch   400  of    620.    Elapsed: 0:04:08.\n  Batch   440  of    620.    Elapsed: 0:04:33.\n  Batch   480  of    620.    Elapsed: 0:04:58.\n  Batch   520  of    620.    Elapsed: 0:05:22.\n  Batch   560  of    620.    Elapsed: 0:05:47.\n  Batch   600  of    620.    Elapsed: 0:06:12.\n\n  Average training loss: 0.01\n  Training epoch took: 0:06:24\n\nRunning Validation...\n  Accuracy: 0.91\n  Validation took: 0:06:41\n\n======== Epoch 12 / 20 ========\nTraining...\n  Batch    40  of    620.    Elapsed: 0:00:25.\n  Batch    80  of    620.    Elapsed: 0:00:49.\n  Batch   120  of    620.    Elapsed: 0:01:14.\n  Batch   160  of    620.    Elapsed: 0:01:39.\n  Batch   200  of    620.    Elapsed: 0:02:04.\n  Batch   240  of    620.    Elapsed: 0:02:28.\n  Batch   280  of    620.    Elapsed: 0:02:53.\n  Batch   320  of    620.    Elapsed: 0:03:18.\n  Batch   360  of    620.    Elapsed: 0:03:43.\n  Batch   400  of    620.    Elapsed: 0:04:08.\n  Batch   440  of    620.    Elapsed: 0:04:32.\n  Batch   480  of    620.    Elapsed: 0:04:57.\n  Batch   520  of    620.    Elapsed: 0:05:22.\n  Batch   560  of    620.    Elapsed: 0:05:47.\n  Batch   600  of    620.    Elapsed: 0:06:11.\n\n  Average training loss: 0.01\n  Training epoch took: 0:06:23\n\nRunning Validation...\n  Accuracy: 0.91\n  Validation took: 0:06:40\n\n======== Epoch 13 / 20 ========\nTraining...\n  Batch    40  of    620.    Elapsed: 0:00:25.\n  Batch    80  of    620.    Elapsed: 0:00:50.\n  Batch   120  of    620.    Elapsed: 0:01:14.\n  Batch   160  of    620.    Elapsed: 0:01:39.\n  Batch   200  of    620.    Elapsed: 0:02:04.\n  Batch   240  of    620.    Elapsed: 0:02:29.\n  Batch   280  of    620.    Elapsed: 0:02:53.\n  Batch   320  of    620.    Elapsed: 0:03:18.\n  Batch   360  of    620.    Elapsed: 0:03:43.\n  Batch   400  of    620.    Elapsed: 0:04:07.\n  Batch   440  of    620.    Elapsed: 0:04:32.\n  Batch   480  of    620.    Elapsed: 0:04:57.\n  Batch   520  of    620.    Elapsed: 0:05:22.\n  Batch   560  of    620.    Elapsed: 0:05:47.\n  Batch   600  of    620.    Elapsed: 0:06:11.\n\n  Average training loss: 0.01\n  Training epoch took: 0:06:24\n\nRunning Validation...\n  Accuracy: 0.91\n  Validation took: 0:06:40\n\n======== Epoch 14 / 20 ========\nTraining...\n  Batch    40  of    620.    Elapsed: 0:00:25.\n  Batch    80  of    620.    Elapsed: 0:00:50.\n  Batch   120  of    620.    Elapsed: 0:01:14.\n  Batch   160  of    620.    Elapsed: 0:01:39.\n  Batch   200  of    620.    Elapsed: 0:02:04.\n  Batch   240  of    620.    Elapsed: 0:02:29.\n  Batch   280  of    620.    Elapsed: 0:02:54.\n  Batch   320  of    620.    Elapsed: 0:03:18.\n  Batch   360  of    620.    Elapsed: 0:03:43.\n  Batch   400  of    620.    Elapsed: 0:04:08.\n  Batch   440  of    620.    Elapsed: 0:04:33.\n  Batch   480  of    620.    Elapsed: 0:04:58.\n  Batch   520  of    620.    Elapsed: 0:05:22.\n  Batch   560  of    620.    Elapsed: 0:05:47.\n  Batch   600  of    620.    Elapsed: 0:06:12.\n\n  Average training loss: 0.00\n  Training epoch took: 0:06:24\n\nRunning Validation...\n  Accuracy: 0.91\n  Validation took: 0:06:41\n\n======== Epoch 15 / 20 ========\nTraining...\n  Batch    40  of    620.    Elapsed: 0:00:25.\n  Batch    80  of    620.    Elapsed: 0:00:49.\n  Batch   120  of    620.    Elapsed: 0:01:14.\n  Batch   160  of    620.    Elapsed: 0:01:39.\n  Batch   200  of    620.    Elapsed: 0:02:04.\n  Batch   240  of    620.    Elapsed: 0:02:29.\n  Batch   280  of    620.    Elapsed: 0:02:54.\n  Batch   320  of    620.    Elapsed: 0:03:18.\n  Batch   360  of    620.    Elapsed: 0:03:43.\n  Batch   400  of    620.    Elapsed: 0:04:08.\n  Batch   440  of    620.    Elapsed: 0:04:33.\n  Batch   480  of    620.    Elapsed: 0:04:57.\n  Batch   520  of    620.    Elapsed: 0:05:22.\n  Batch   560  of    620.    Elapsed: 0:05:47.\n  Batch   600  of    620.    Elapsed: 0:06:12.\n\n  Average training loss: 0.01\n  Training epoch took: 0:06:24\n\nRunning Validation...\n  Accuracy: 0.91\n  Validation took: 0:06:40\n\n======== Epoch 16 / 20 ========\nTraining...\n  Batch    40  of    620.    Elapsed: 0:00:25.\n  Batch    80  of    620.    Elapsed: 0:00:50.\n  Batch   120  of    620.    Elapsed: 0:01:14.\n  Batch   160  of    620.    Elapsed: 0:01:39.\n  Batch   200  of    620.    Elapsed: 0:02:04.\n  Batch   240  of    620.    Elapsed: 0:02:29.\n  Batch   280  of    620.    Elapsed: 0:02:54.\n  Batch   320  of    620.    Elapsed: 0:03:18.\n  Batch   360  of    620.    Elapsed: 0:03:43.\n  Batch   400  of    620.    Elapsed: 0:04:08.\n  Batch   440  of    620.    Elapsed: 0:04:33.\n  Batch   480  of    620.    Elapsed: 0:04:58.\n  Batch   520  of    620.    Elapsed: 0:05:23.\n  Batch   560  of    620.    Elapsed: 0:05:47.\n  Batch   600  of    620.    Elapsed: 0:06:12.\n\n  Average training loss: 0.00\n  Training epoch took: 0:06:24\n\nRunning Validation...\n  Accuracy: 0.91\n  Validation took: 0:06:41\n\n======== Epoch 17 / 20 ========\nTraining...\n  Batch    40  of    620.    Elapsed: 0:00:25.\n  Batch    80  of    620.    Elapsed: 0:00:50.\n  Batch   120  of    620.    Elapsed: 0:01:14.\n  Batch   160  of    620.    Elapsed: 0:01:39.\n  Batch   200  of    620.    Elapsed: 0:02:04.\n  Batch   240  of    620.    Elapsed: 0:02:29.\n  Batch   280  of    620.    Elapsed: 0:02:54.\n  Batch   320  of    620.    Elapsed: 0:03:18.\n  Batch   360  of    620.    Elapsed: 0:03:43.\n  Batch   400  of    620.    Elapsed: 0:04:08.\n  Batch   440  of    620.    Elapsed: 0:04:33.\n  Batch   480  of    620.    Elapsed: 0:04:57.\n  Batch   520  of    620.    Elapsed: 0:05:22.\n  Batch   560  of    620.    Elapsed: 0:05:47.\n  Batch   600  of    620.    Elapsed: 0:06:12.\n\n  Average training loss: 0.00\n  Training epoch took: 0:06:24\n\nRunning Validation...\n  Accuracy: 0.91\n  Validation took: 0:06:40\n\n======== Epoch 18 / 20 ========\nTraining...\n  Batch    40  of    620.    Elapsed: 0:00:25.\n  Batch    80  of    620.    Elapsed: 0:00:50.\n  Batch   120  of    620.    Elapsed: 0:01:14.\n  Batch   160  of    620.    Elapsed: 0:01:39.\n  Batch   200  of    620.    Elapsed: 0:02:04.\n  Batch   240  of    620.    Elapsed: 0:02:29.\n  Batch   280  of    620.    Elapsed: 0:02:53.\n  Batch   320  of    620.    Elapsed: 0:03:18.\n  Batch   360  of    620.    Elapsed: 0:03:43.\n  Batch   400  of    620.    Elapsed: 0:04:08.\n  Batch   440  of    620.    Elapsed: 0:04:33.\n  Batch   480  of    620.    Elapsed: 0:04:57.\n  Batch   520  of    620.    Elapsed: 0:05:22.\n  Batch   560  of    620.    Elapsed: 0:05:47.\n  Batch   600  of    620.    Elapsed: 0:06:12.\n\n  Average training loss: 0.00\n  Training epoch took: 0:06:24\n\nRunning Validation...\n  Accuracy: 0.91\n  Validation took: 0:06:40\n\n======== Epoch 19 / 20 ========\nTraining...\n  Batch    40  of    620.    Elapsed: 0:00:25.\n  Batch    80  of    620.    Elapsed: 0:00:50.\n  Batch   120  of    620.    Elapsed: 0:01:14.\n  Batch   160  of    620.    Elapsed: 0:01:39.\n  Batch   200  of    620.    Elapsed: 0:02:04.\n  Batch   240  of    620.    Elapsed: 0:02:29.\n  Batch   280  of    620.    Elapsed: 0:02:54.\n  Batch   320  of    620.    Elapsed: 0:03:18.\n  Batch   360  of    620.    Elapsed: 0:03:43.\n  Batch   400  of    620.    Elapsed: 0:04:08.\n  Batch   440  of    620.    Elapsed: 0:04:33.\n  Batch   480  of    620.    Elapsed: 0:04:58.\n  Batch   520  of    620.    Elapsed: 0:05:22.\n  Batch   560  of    620.    Elapsed: 0:05:47.\n  Batch   600  of    620.    Elapsed: 0:06:12.\n\n  Average training loss: 0.00\n  Training epoch took: 0:06:24\n\nRunning Validation...\n  Accuracy: 0.91\n  Validation took: 0:06:41\n\n======== Epoch 20 / 20 ========\nTraining...\n  Batch    40  of    620.    Elapsed: 0:00:25.\n  Batch    80  of    620.    Elapsed: 0:00:50.\n  Batch   120  of    620.    Elapsed: 0:01:14.\n  Batch   160  of    620.    Elapsed: 0:01:39.\n  Batch   200  of    620.    Elapsed: 0:02:04.\n  Batch   240  of    620.    Elapsed: 0:02:29.\n  Batch   280  of    620.    Elapsed: 0:02:54.\n  Batch   320  of    620.    Elapsed: 0:03:18.\n  Batch   360  of    620.    Elapsed: 0:03:43.\n  Batch   400  of    620.    Elapsed: 0:04:08.\n  Batch   440  of    620.    Elapsed: 0:04:33.\n  Batch   480  of    620.    Elapsed: 0:04:58.\n  Batch   520  of    620.    Elapsed: 0:05:22.\n  Batch   560  of    620.    Elapsed: 0:05:47.\n  Batch   600  of    620.    Elapsed: 0:06:12.\n\n  Average training loss: 0.00\n  Training epoch took: 0:06:24\n\nRunning Validation...\n  Accuracy: 0.91\n  Validation took: 0:06:41\n","output_type":"stream"}]},{"cell_type":"code","source":"# Plotting training loss and accuracy\nplt.figure(figsize=(12, 6))\n\n# Plot training loss\nplt.subplot(1, 2, 1)\nplt.plot(loss_values, 'b-o')\nplt.title(\"Training Loss\")\nplt.xlabel(\"Epoch\")\nplt.ylabel(\"Loss\")\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-04-28T19:21:47.683091Z","iopub.execute_input":"2024-04-28T19:21:47.683774Z","iopub.status.idle":"2024-04-28T19:21:47.926209Z","shell.execute_reply.started":"2024-04-28T19:21:47.683741Z","shell.execute_reply":"2024-04-28T19:21:47.925293Z"},"trusted":true},"execution_count":17,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 1200x600 with 1 Axes>","image/png":"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"},"metadata":{}}]},{"cell_type":"code","source":"# Calculate Matthews Correlation Coefficient\npredictions, true_labels = [], []\nfor batch in validation_dataloader:\n    batch = tuple(t.to(device) for t in batch)\n    b_input_ids, b_input_mask, b_labels = batch\n    with torch.no_grad():\n        outputs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)\n    logits = outputs[0]\n    logits = logits.detach().cpu().numpy()\n    label_ids = b_labels.to('cpu').numpy()\n    predictions.append(logits)\n    true_labels.append(label_ids)\nflat_predictions = np.argmax(np.concatenate(predictions, axis=0), axis=1).flatten()\nflat_true_labels = np.concatenate(true_labels, axis=0).flatten()\nmcc = matthews_corrcoef(flat_true_labels, flat_predictions)\nprint('MCC: %.3f' % mcc)","metadata":{"execution":{"iopub.status.busy":"2024-04-28T19:21:53.079224Z","iopub.execute_input":"2024-04-28T19:21:53.079624Z","iopub.status.idle":"2024-04-28T19:22:09.248880Z","shell.execute_reply.started":"2024-04-28T19:21:53.079594Z","shell.execute_reply":"2024-04-28T19:22:09.247893Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"MCC: 0.756\n","output_type":"stream"}]},{"cell_type":"code","source":"# Classification report\nfrom sklearn.metrics import classification_report\nprint(classification_report(flat_true_labels, flat_predictions))","metadata":{"execution":{"iopub.status.busy":"2024-04-28T19:22:11.478329Z","iopub.execute_input":"2024-04-28T19:22:11.478740Z","iopub.status.idle":"2024-04-28T19:22:11.498138Z","shell.execute_reply.started":"2024-04-28T19:22:11.478707Z","shell.execute_reply":"2024-04-28T19:22:11.497209Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"              precision    recall  f1-score   support\n\n           0       0.48      0.39      0.43       142\n           1       0.94      0.95      0.95      1902\n           2       0.89      0.89      0.89       435\n\n    accuracy                           0.91      2479\n   macro avg       0.77      0.75      0.76      2479\nweighted avg       0.90      0.91      0.91      2479\n\n","output_type":"stream"}]}]}